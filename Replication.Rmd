---
title: "Replication of \"Community-Based Fact-Checking on Twitter's Birdwatch Platform\""
author: "Dereck Taverne(CUNY/ Baruch College) & Ahmed Lotfi (Wagner College)"
date: "6/20/2025"
output:
  html_document:
    theme: readable
    toc: true
    toc_float: true
    code_folding: hide
---
# Used Libraries 
```{r setup, include=FALSE}
library(here)
library(scales)
library(tidyverse)
library(ggplot2)
library(stringr)

knitr::opts_chunk$set(echo = TRUE)
```
# Overview: 
In this project, we are trying to replicate figures: 2,3,4,5C,7C,8,9,10 from the "Community-Based Fact-Checking on Twitter's Birdwatch Platform". You can find the original paper [here](https://arxiv.org/pdf/2104.07175). 
We couldn't get the same exact data the author used. We got a very similiar data. In our data, we have 9,377 notes and 45,885 ratings. In the original paper, the author had 11,802 notes and 52,981 ratings. 

# Loading Data
We are loading 2 files: notes and ratings for the these notes after downloading from Birdwatch publicly avaliable Data

### Disclamer: 
We have a slightly different data comparing to the one the author used in the paper. 

```{r load data, warning=FALSE, message=FALSE}


notes <- read_tsv("Data/notes.tsv")
view(notes)

ratings <- read_tsv("Data/ratings.tsv")
view(ratings)

notes_with_ratings <- left_join(notes, ratings, by = "noteId") 

notes_with_ratingsIJ <-inner_join(notes, ratings, by = "noteId")

view(notes_with_ratings)

```


# Figure 2 Replication:Number of users who responded “Yes” to the question “Did you link to sources you believe most people would consider trustworthy?”

```{r work on Figure 2, warning=FALSE, message=FALSE}
work_figure_2 <- notes_with_ratings |> group_by(classification, trustworthySources) |> summarise(count = n_distinct(noteId))
view(work_figure_2)

# change levels of trustworthySources (0,1) to (Trustworthy Sources, No trustworthy Sources) then order the levels for the graph 
work_figure_2 <- work_figure_2 |> mutate(
    trustworthySources = factor(trustworthySources, levels = c(1,0), labels =  c("Trustworthy Sources" , "No trustworthy Sources"))
) 
work_figure_2$trustworthySources <- factor(work_figure_2$trustworthySources, levels = c("No trustworthy Sources", "Trustworthy Sources"))


# Change column classification to factor from chr then order the levels for the graph
work_figure_2$classification <- as.factor(work_figure_2$classification)
work_figure_2$classification <- factor(work_figure_2$classification, levels = c("NOT_MISLEADING", "MISINFORMED_OR_POTENTIALLY_MISLEADING"))


# plot the graph 
work_figure_2 |> ggplot(aes(x =  count, y = classification, fill = trustworthySources)) +
geom_bar(stat = "identity", width = 0.1) + 
scale_fill_manual(
    values = c("No trustworthy Sources" = "yellow", "Trustworthy Sources" = "#4141db")) + 
labs(
    x = "Number of Users", 
    y = "Classification", 
    fill = "Trustworthy Sources"
)
```

## Figure 2 Report & discription: 
    As a try to replicate figure 2, we got a very similiar results to the original paper. We believe that the differences between our figure and the figure in the original data is due to the slight difference in the dataset. 
    Our findings are: 
    Notes that reported the tweet as Misleading & believe they included trustworthy sources: 6026
    Notes that reported the tweet as Misleading & don't have trustworthy sources: 2094
    Notes that reported the tweet as not-misleading & believe they included trustworthy sources: 728
    Notes that reorted the tweet as Misleading & don't have trustworthy sources: 529


# Figure 3 Replication: 
```{r work on Figure 3, warning=FALSE, message=FALSE}

view(notes_with_ratings)

work_figure_3 <- notes_with_ratings |> filter(classification == "MISINFORMED_OR_POTENTIALLY_MISLEADING")

work_figure_3 <- work_figure_3 |> 
select(noteId, 
    misleadingFactualError, 
    misleadingMissingImportantContext,
    misleadingUnverifiedClaimAsFact, 
    misleadingOutdatedInformation, 
    misleadingOther, 
    misleadingSatire, 
    misleadingManipulatedMedia) 

work_figure_3 <- work_figure_3 |> pivot_longer(cols = -noteId, names_to = "Reason", values_to = "Flag")

work_figure_3 <-  work_figure_3 |> filter(Flag == 1)
work_figure_3 <- work_figure_3 |> group_by(Reason) |> summarise(Number_Notes = n_distinct(noteId))

work_figure_3 |> ggplot(aes(x = Number_Notes, y = reorder(Reason, Number_Notes))) +
geom_bar(stat = "identity", fill = "red", width = 0.2) + 
labs(
    x = "Number of Birdwatch Notes", 
    y = "Reason"
)



```

## Figure 3 Description: 
Number of Birdwatch notes per checkbox answer option in response to the question “Why do you believe this tweet may be misleading?


# Figure 4 Replication: 
```{r work Figure 4, warning=FALSE, message=FALSE}

view(notes)


work_figure_4 <- notes_with_ratings |> filter(classification == "NOT_MISLEADING")

work_figure_4 <- work_figure_4 |> 
select(
    noteId,
    notMisleadingOther, 
    notMisleadingFactuallyCorrect, 
    notMisleadingOutdatedButNotWhenWritten, 
    notMisleadingClearlySatire, 
    notMisleadingPersonalOpinion, 
    )
work_figure_4 <- work_figure_4 |> pivot_longer(cols = -noteId, names_to = "Reason", values_to = "Flag")
work_figure_4 <- work_figure_4 |> filter(Flag == 1)
work_figure_4 <- work_figure_4|> group_by(Reason) |> summarise(Number_Notes = n_distinct(noteId))

view(work_figure_4)

work_figure_4 |> ggplot(aes(x = Number_Notes, y = reorder(Reason, Number_Notes))) +
geom_bar(stat = "identity", fill = "#0e0e6b", width = 0.2) + 
labs(
    x = "Number of Birdwatch Notes", 
    y = "Reason"
)

```

## Figure 4 Description: 
Number of Birdwatch notes per checkbox answer option in response to the question “Why do you believe this tweet is not misleading?


# Figure 5C Replication as the paper:
In this figure, we counted the words in the summary similiar to what the author did. We are counting the words in the URL as well as the the description.

```{r work Figure 5C as the paper, warning=FALSE, message=FALSE}

work_figure_5_c_as_the_paper <- notes_with_ratings |> distinct(noteId, .keep_all = TRUE)

work_figure_5_c_as_the_paper <- work_figure_5_c_as_the_paper |> mutate(wordcount = str_count(summary, boundary("word")))

view(work_figure_5_c_as_the_paper)

work_figure_5_c_as_the_paper <- work_figure_5_c_as_the_paper |> group_by(classification) |> arrange(wordcount) |> 
mutate(
    rank = row_number(), 
    n = n(), 
    CCDF = 1- (rank-1) /n)

    # (rank-1) /n  ==> the fraction of the tweets that have wordcount smaller than the current 

work_figure_5_c_as_the_paper |> ggplot(aes(x = wordcount, y = CCDF, color = classification)) + 
geom_line() + 
scale_y_log10(
    labels = scales::percent_format(accuracy = 0.01), 
    breaks = c(0.0001, 0.001, 0.01, 0.1, 1)
    )
```


## Figure 5C as the paper Description: 
The figure shows CCDF (Complementary Cumulative Distribution Function) for the word count 


# Figure 5C our understanding:
Here, we changed the any links to be only one word, which is "URL". So, there is significant reduction in the total number of words per note

```{r work Figure 5C our figure, warning=FALSE, message=FALSE}

#view(notes_with_ratings |> filter(noteId == 1399427393106825200)) 


work_figure_5_c <- notes_with_ratings |> distinct(noteId, .keep_all = TRUE)

#To change the URL to be counted as one word
work_figure_5_c <- work_figure_5_c |> mutate(
   clean_summary = summary |> str_replace_all("(https?://)?(www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}[^\\s]*", "URL")
)

work_figure_5_c <- work_figure_5_c |> mutate(wordcount = str_count(clean_summary, boundary("word")))

view(work_figure_5_c)

work_figure_5_c <- work_figure_5_c |> group_by(classification) |> arrange(wordcount) |> 
mutate(
    rank = row_number(), 
    n = n(), 
    CCDF = 1- (rank-1) /n)

    # (rank-1) /n  ==> the fraction of the tweets that have wordcount smaller than the current 

    view(work_figure_5_c)

work_figure_5_c |> ggplot(aes(x = wordcount, y = CCDF, color = classification)) + 
geom_line() + 
scale_y_log10(
    labels = scales::percent_format(accuracy = 0.01), 
    breaks = c(0.0001, 0.001, 0.01, 0.1, 1)
    )
```

## Figure 5C our understanding Description: 
The figure shows CCDF (Complementary Cumulative Distribution Function) for the word count 


# Figure 7 Replication: 

```{r figure-7a, warning=FALSE, message=FALSE}
work_figure_7a <- notes_with_ratingsIJ |> 
    group_by(classification, noteId) |>
    summarize(helpful_count = sum(helpful, na.rm = TRUE), votes_count = n()) |>
    mutate(helpful_ratio = helpful_count / votes_count) |>
    arrange(helpful_ratio) |>
    mutate(
        rank = min_rank(helpful_ratio), 
        n = n(), 
        CCDF = 1 - (rank -1)/n
    )

view(work_figure_7a)

work_figure_7a |> ggplot(aes(x = helpful_ratio, y = CCDF, color = classification)) +
    geom_line() +  
    scale_y_log10(
        breaks = c(0,0.25,0.5,1), 
        labels = scales::percent_format(accuracy = 1)
    )
```

## Figure 7a Description: 
CCDFs for helpfulness ratio grouped by the classification of the notes: misleading or not misleading


# Figure 7b Replication:

```{r figure-7b, warning=FALSE, message=FALSE}

work_figure_7b<- notes_with_ratingsIJ |>
     group_by(classification, noteId) |>
    summarize(votes_count = n()) |>
    arrange(votes_count) |>
    mutate(
        rank = min_rank(votes_count), 
        n = n(), 
        CCDF = 1 - (rank -1)/n
    )

work_figure_7b |> ggplot(aes(x = votes_count, y = CCDF, color = classification)) +
    geom_line() +
    scale_y_log10(
        breaks = c(0.0001, 0.001, 0.01, 0.1, 1),
        labels = scales::percent_format()
        
    )
```

## Figure 7b Description: 
The figures shows the CCDFs for total votes grouped by the classification of the note

# Figure 8 Replication: 
```{r figure_8}
figure_8_helpful <- notes_with_ratingsIJ |>
    select(
        noteId,
        helpfulOther,
        helpfulInformative,
        helpfulClear,
        helpfulEmpathetic,
        helpfulGoodSources,
        helpfulUniqueContext,
        helpfulAddressesClaim,
        helpfulImportantContext,
    )


figure_8_longer <- figure_8_helpful |> pivot_longer(cols = -noteId, names_to = "Reason", values_to = "Flag")


figure_8_longer <- figure_8_longer |> filter(Flag == 1)

figure_8_longer <- figure_8_longer |>
    group_by(Reason) |>
    summarise(Number_of_Ratings = n())

figure_8_longer |> ggplot(aes(x = Number_of_Ratings, y = reorder(Reason, Number_of_Ratings))) +
    geom_bar(stat = "identity", fill = "blue", width = 0.2) +
    labs(
        x = "Number of Ratings",
        y = "Reason"
    )
```

## Figure 8 Description: 
Number of ratings per checkbox answer option in response to the prompt “What about this note was helpful to you?

# Figure 9 Replication: 
```{r figure_9, warning=FALSE, message=FALSE}
figure_9_helpful <- notes_with_ratingsIJ |>
    select(
        noteId,
        notHelpfulSourcesMissingOrUnreliable,
        notHelpfulOpinionSpeculationOrBias,
        notHelpfulMissingKeyPoints,
        notHelpfulArgumentativeOrBiased,
        notHelpfulIncorrect,
        notHelpfulOffTopic,
        notHelpfulOther,
        notHelpfulHardToUnderstand,
        notHelpfulSpamHarassmentOrAbuse,
        notHelpfulOutdated,
        notHelpfulIrrelevantSources,
    )

figure_9_longer <- figure_9_helpful |> pivot_longer(cols = -noteId, names_to = "Reason", values_to = "Flag")

view(figure_9_longer)

figure_9_longer <- figure_9_longer |> filter(Flag == 1)
figure_9_longer <- figure_9_longer |>
    group_by(Reason) |>
    summarise(Number_of_Ratings = n())

figure_9_longer |> ggplot(aes(x = Number_of_Ratings, y = reorder(Reason, Number_of_Ratings))) +
    geom_bar(stat = "identity", fill = "red", width = 0.2) +
    labs(
        x = "Number of Ratings",
        y = "Reason"
    )
```

## Figure 9 Description: 
Number of ratings per checkbox answer option in response to the question “Help us understand why this note was unhelpful. 


# Figure 10 Replication: 

```{r figure_10, warning=FALSE, message=FALSE}
tweets <- load("Data/source_tweets.Rdata")
tweets <- get(tweets)


tweets <- tweets |> select(
    noteId, 
    tweetId, 
    source_followers_count, 
    source_verified, 
    source_friends_count, 
    source_account_created_at,
)

tweets_with_ratings <- inner_join(tweets, notes_with_ratingsIJ, by="noteId")

view(tweets_with_ratings)


current_date <- Sys.Date()
current_year <- format(current_date, "%Y")

tweets_with_ratings <- tweets_with_ratings |> mutate(
    account_age = as.numeric(current_year) - as.numeric(year(tweets_with_ratings$source_account_created_at)),
    word_count = str_count(summary, boundary("word")),
    classification = ifelse(classification == "MISINFORMED_OR_POTENTIALLY_MISLEADING", 1, 0)
    )

tweets_with_ratings <- tweets_with_ratings |> mutate(
    source_followers_count = scale(source_followers_count), 
    source_friends_count = scale(source_friends_count), 
    account_age = scale(account_age), 
    word_count = scale(word_count), 
) |> group_by(noteId) |> 
mutate(
    total_votes = n(),
    helpful_num  = sum(helpful),
    helpful_ratio = helpful_num/ total_votes, 
)


view(tweets_with_ratings)

model <- glm(helpful_ratio ~ (source_followers_count + source_verified + source_friends_count + account_age + word_count + classification + trustworthySources), data = tweets_with_ratings, family = "binomial")

coef_data <- enframe(coef(model))

coef_data <- coef_data |> mutate(
    stderr = enframe(summary(model)$coefficients[, "Std. Error"])$value
) |> filter(name != "(Intercept)")


coef_data |> ggplot(aes(x = name, y = value)) + geom_point(size=5, color = "#5bc05b") + 
geom_errorbar(aes(ymin = value - (stderr * 2.58), ymax = value + (stderr* 2.58)), width = 0.2, color = "5bc05b") 
```

## Figure 10 Description: 
Number of ratings per checkbox answer option in response to the prompt “What about this note was helpful to you?

# Extension Ideas: 

1. How do features of the notes, such as politeness and specificity in Birdwatch notes, influence their helpfulness ratio (helpful votes to the total count)?  (We can use built-in libraries for politeness in R or trained libraries such as Stanford's Politeness API.) 

   a- Possible Independent variables: Framing type, politeness score, specificity score, emotional tone, sentiment, length, etc.
   
   b- Dependent: helpful ratio 

1. How does the timing of Birdwatch notes (early vs. late after tweet publication) affect their influence on tweet engagement and misinformation spread?

2. Do Birdwatch notes affect the behavior of the original tweet authors (e.g., deleting tweets, posting follow-ups, changing tone)

3. How do different user demographics (e.g., follower count, verification status, tweet topic) influence which tweets get fact-checked on Birdwatch?
